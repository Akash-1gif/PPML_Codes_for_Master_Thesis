{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Ki2ryWhjOWO5",
        "outputId": "6bd42d7e-c0ea-4d66-8a83-bac1d7a4268d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for axis 1 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2640181367ac>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# McNemar's Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mcontingency_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_manual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_sklearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcnemar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingency_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mmcnemar_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmcnemar_p_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/stats/contingency_tables.py\u001b[0m in \u001b[0;36mmcnemar\u001b[0;34m(table, exact, correction)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_df_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m     \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have predictions and true labels\n",
        "y_true = np.array([-1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
        "       -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
        "       -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
        "       -1, -1, -1, -1, -1])  # True labels\n",
        "y_pred_manual = np.array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])  # Predictions from manually trained model\n",
        "y_pred_sklearn = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1])  # Predictions from sklearn model\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_manual = accuracy_score(y_true, y_pred_manual)\n",
        "accuracy_sklearn = accuracy_score(y_true, y_pred_sklearn)\n",
        "\n",
        "# Calculate other metrics\n",
        "precision_manual = precision_score(y_true, y_pred_manual, average='weighted')\n",
        "precision_sklearn = precision_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "recall_manual = recall_score(y_true, y_pred_manual, average='weighted')\n",
        "recall_sklearn = recall_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "f1_manual = f1_score(y_true, y_pred_manual, average='weighted')\n",
        "f1_sklearn = f1_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "# Calculate Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_pred_manual, y_pred_sklearn)\n",
        "\n",
        "# McNemar's Test\n",
        "contingency_table = confusion_matrix(y_pred_manual, y_pred_sklearn)\n",
        "result = mcnemar(contingency_table, exact=True)\n",
        "mcnemar_stat = result.statistic\n",
        "mcnemar_p_value = result.pvalue\n",
        "\n",
        "print(f\"Accuracy Manual: {accuracy_manual}\")\n",
        "print(f\"Accuracy Sklearn: {accuracy_sklearn}\")\n",
        "print(f\"Precision Manual: {precision_manual}\")\n",
        "print(f\"Precision Sklearn: {precision_sklearn}\")\n",
        "print(f\"Recall Manual: {recall_manual}\")\n",
        "print(f\"Recall Sklearn: {recall_sklearn}\")\n",
        "print(f\"F1 Score Manual: {f1_manual}\")\n",
        "print(f\"F1 Score Sklearn: {f1_sklearn}\")\n",
        "print(f\"Cohen's Kappa: {kappa}\")\n",
        "print(f\"McNemar's Test Statistic: {mcnemar_stat}, p-value: {mcnemar_p_value}\")\n",
        "\n",
        "# Paired t-test on accuracies (optional, needs accuracy on same samples)\n",
        "# paired_t_stat, paired_t_p_value = stats.ttest_rel(y_pred_manual == y_true, y_pred_sklearn == y_true)\n",
        "# print(f\"Paired t-test on accuracies: t-statistic: {paired_t_stat}, p-value: {paired_t_p_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_pred_sklearn,y_pred_manual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwH9Q2JsOxqF",
        "outputId": "309a76f3-225d-4055-a896-be81b59cb6bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxtHokIYoyhR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}