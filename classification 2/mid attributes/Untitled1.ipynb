{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08fa902-0edb-4669-b21d-f9fc52577fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257ee351-f752-4dca-8284-200d7997e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return expit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5469653d-7e6d-47ee-a1a5-acf5facd5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(y_true, y_pred):\n",
    "#     return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58723d24-0a0f-4e35-a4d5-401c8cafe7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_sgd(X_train, y_train, learning_rate=0.1, n_iter=3):\n",
    "    n_samples, n_features = X_train.shape\n",
    "    # Initialize weights and bias\n",
    "    np.random.seed(42)\n",
    "    weights = np.random.randn(n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    # Iterate for n_iter epochs\n",
    "    for epoch in range(n_iter):\n",
    "        total_loss = 0\n",
    "        for i in range(n_samples):\n",
    "            # Select a random data point\n",
    "            rand_idx = np.random.randint(n_samples)\n",
    "            X_i = X_train[rand_idx]\n",
    "            y_i = y_train[rand_idx]\n",
    "            \n",
    "            # Compute prediction\n",
    "            z = np.dot(X_i, weights) + bias\n",
    "            y_pred = sigmoid(z)\n",
    "            \n",
    "            # Compute gradients\n",
    "            gradient = (y_pred - y_i) * X_i\n",
    "            bias_gradient = (y_pred - y_i)\n",
    "            \n",
    "            # Update weights and bias\n",
    "            weights -= learning_rate * gradient\n",
    "            bias -= learning_rate * bias_gradient\n",
    "            \n",
    "            # Compute current loss (for monitoring purposes)\n",
    "            # total_loss += compute_loss(y_i, y_pred)\n",
    "        \n",
    "        # Print average loss for the epoch\n",
    "        # avg_loss = total_loss / n_samples\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print(f'Epoch {epoch}, Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c9e3a4-1c1f-4d73-9ca9-8e9cc606b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, bias):\n",
    "    z = np.dot(X, weights) + bias\n",
    "    y_pred = sigmoid(z)\n",
    "    return (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9639a898-0e80-4478-b477-b85eca61a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train=pd.read_csv('X_train1.csv')\n",
    "X_train=X_train.to_numpy()\n",
    "X_test=pd.read_csv('X_test1.csv')\n",
    "X_test=X_test.to_numpy()\n",
    "y_train=pd.read_csv('y_train1.csv')\n",
    "y_train=y_train.to_numpy()\n",
    "y_train=y_train.reshape(-1)\n",
    "y_test=pd.read_csv('y_test1.csv')\n",
    "y_test=y_test.to_numpy()\n",
    "y_test=y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a06ac5-9024-4f8b-a09b-ee284adbe7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = logistic_regression_sgd(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da27fa2-a46a-4912-a092-7fff63cc8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31902dfb-e2e5-4e24-a002-16bba609d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4b2a4d-3a7e-43f2-9140-0c11a464420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.89671415,  20.46173575,  -1.25231146,   1.82302986,\n",
       "        11.26584664,   0.06586304,   1.57921282,   3.16743473,\n",
       "        -0.46947439, -58.85743973,  56.68658243,  -5.41572967,\n",
       "       -11.4950377 , -37.21328017,   6.47508225])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d25c28-e1d4-4eef-b481-cc592c8acb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='saga', max_iter=3, C=1.0)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4ab295-d597-4ceb-b93a-259cc8c9c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71291970e-04,  3.30044054e-03, -7.58323576e-04,  3.94520503e-05,\n",
       "        3.11199338e-03, -6.94705758e-06,  3.35778347e-05,  3.77176811e-04,\n",
       "        1.15765227e-05, -1.37069739e-02,  1.20186866e-02, -5.60656951e-04,\n",
       "       -3.99210351e-03, -4.93129490e-03,  2.55930179e-03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca9bdf-bbd3-4dda-bf0f-62dd47f8fc61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
