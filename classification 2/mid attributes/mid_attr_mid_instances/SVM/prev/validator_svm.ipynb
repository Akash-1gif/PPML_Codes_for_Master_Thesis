{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki2ryWhjOWO5",
        "outputId": "04b86271-3600-4fee-f475-49e19b187d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Manual: 0.8470588235294118\n",
            "Accuracy Sklearn: 0.8176470588235294\n",
            "Precision Manual: 0.7175086505190311\n",
            "Precision Sklearn: 0.7547761133438883\n",
            "Recall Manual: 0.8470588235294118\n",
            "Recall Sklearn: 0.8176470588235294\n",
            "F1 Score Manual: 0.7769201948295241\n",
            "F1 Score Sklearn: 0.7784433117509297\n",
            "Cohen's Kappa: 0.0\n",
            "McNemar's Test Statistic: 0.0, p-value: 0.00390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have predictions and true labels\n",
        "y_true = np.array([-1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
        "       -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1,\n",
        "       -1, -1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
        "        1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1,\n",
        "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1,  1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
        "       -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])  # True labels\n",
        "y_pred_manual = np.array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
        "       -1.])  # Predictions from manually trained model\n",
        "y_pred_sklearn = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
        "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1])  # Predictions from sklearn model\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_manual = accuracy_score(y_true, y_pred_manual)\n",
        "accuracy_sklearn = accuracy_score(y_true, y_pred_sklearn)\n",
        "\n",
        "# Calculate other metrics\n",
        "precision_manual = precision_score(y_true, y_pred_manual, average='weighted')\n",
        "precision_sklearn = precision_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "recall_manual = recall_score(y_true, y_pred_manual, average='weighted')\n",
        "recall_sklearn = recall_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "f1_manual = f1_score(y_true, y_pred_manual, average='weighted')\n",
        "f1_sklearn = f1_score(y_true, y_pred_sklearn, average='weighted')\n",
        "\n",
        "# Calculate Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_pred_manual, y_pred_sklearn)\n",
        "\n",
        "# McNemar's Test\n",
        "contingency_table = confusion_matrix(y_pred_manual, y_pred_sklearn)\n",
        "result = mcnemar(contingency_table, exact=True)\n",
        "mcnemar_stat = result.statistic\n",
        "mcnemar_p_value = result.pvalue\n",
        "\n",
        "print(f\"Accuracy Manual: {accuracy_manual}\")\n",
        "print(f\"Accuracy Sklearn: {accuracy_sklearn}\")\n",
        "print(f\"Precision Manual: {precision_manual}\")\n",
        "print(f\"Precision Sklearn: {precision_sklearn}\")\n",
        "print(f\"Recall Manual: {recall_manual}\")\n",
        "print(f\"Recall Sklearn: {recall_sklearn}\")\n",
        "print(f\"F1 Score Manual: {f1_manual}\")\n",
        "print(f\"F1 Score Sklearn: {f1_sklearn}\")\n",
        "print(f\"Cohen's Kappa: {kappa}\")\n",
        "print(f\"McNemar's Test Statistic: {mcnemar_stat}, p-value: {mcnemar_p_value}\")\n",
        "\n",
        "# Paired t-test on accuracies (optional, needs accuracy on same samples)\n",
        "# paired_t_stat, paired_t_p_value = stats.ttest_rel(y_pred_manual == y_true, y_pred_sklearn == y_true)\n",
        "# print(f\"Paired t-test on accuracies: t-statistic: {paired_t_stat}, p-value: {paired_t_p_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_pred_sklearn,y_pred_manual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwH9Q2JsOxqF",
        "outputId": "0151a0df-560d-4a55-a131-545e3688cb56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9470588235294117"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxtHokIYoyhR"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}