{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "Ki2ryWhjOWO5",
    "outputId": "deea0620-b972-4f4d-82f0-72230e08798c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:395: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:716: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:395: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# McNemar's Test\u001b[39;00m\n\u001b[0;32m     78\u001b[0m contingency_table \u001b[38;5;241m=\u001b[39m confusion_matrix(y_pred_manual, y_pred_sklearn)\n\u001b[1;32m---> 79\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmcnemar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontingency_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m mcnemar_stat \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstatistic\n\u001b[0;32m     81\u001b[0m mcnemar_p_value \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpvalue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\stats\\contingency_tables.py:1333\u001b[0m, in \u001b[0;36mmcnemar\u001b[1;34m(table, exact, correction)\u001b[0m\n\u001b[0;32m   1331\u001b[0m table \u001b[38;5;241m=\u001b[39m _make_df_square(table)\n\u001b[0;32m   1332\u001b[0m table \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(table, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m-> 1333\u001b[0m n1, n2 \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, table[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact:\n\u001b[0;32m   1336\u001b[0m     statistic \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(n1, n2)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have predictions and true labels\n",
    "y_true = np.array([-1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
    "       -1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
    "       -1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1, -1,  1,\n",
    "       -1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1,\n",
    "        1, -1,  1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,  1, -1, -1,\n",
    "       -1, -1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1,\n",
    "       -1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,\n",
    "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1, -1, -1, -1,\n",
    "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
    "       -1,  1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,\n",
    "       -1, -1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1, -1,  1,\n",
    "        1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1,\n",
    "       -1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
    "        1, -1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,\n",
    "       -1,  1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1])  # True labels\n",
    "y_pred_manual = np.array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
    "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])  # Predictions from manually trained model\n",
    "y_pred_sklearn = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])  # Predictions from sklearn model\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_manual = accuracy_score(y_true, y_pred_manual)\n",
    "accuracy_sklearn = accuracy_score(y_true, y_pred_sklearn)\n",
    "\n",
    "# Calculate other metrics\n",
    "precision_manual = precision_score(y_true, y_pred_manual, average='weighted')\n",
    "precision_sklearn = precision_score(y_true, y_pred_sklearn, average='weighted')\n",
    "\n",
    "recall_manual = recall_score(y_true, y_pred_manual, average='weighted')\n",
    "recall_sklearn = recall_score(y_true, y_pred_sklearn, average='weighted')\n",
    "\n",
    "f1_manual = f1_score(y_true, y_pred_manual, average='weighted')\n",
    "f1_sklearn = f1_score(y_true, y_pred_sklearn, average='weighted')\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa_score(y_pred_manual, y_pred_sklearn)\n",
    "\n",
    "# McNemar's Test\n",
    "contingency_table = confusion_matrix(y_pred_manual, y_pred_sklearn)\n",
    "result = mcnemar(contingency_table, exact=True)\n",
    "mcnemar_stat = result.statistic\n",
    "mcnemar_p_value = result.pvalue\n",
    "\n",
    "print(f\"Accuracy Manual: {accuracy_manual}\")\n",
    "print(f\"Accuracy Sklearn: {accuracy_sklearn}\")\n",
    "print(f\"Precision Manual: {precision_manual}\")\n",
    "print(f\"Precision Sklearn: {precision_sklearn}\")\n",
    "print(f\"Recall Manual: {recall_manual}\")\n",
    "print(f\"Recall Sklearn: {recall_sklearn}\")\n",
    "print(f\"F1 Score Manual: {f1_manual}\")\n",
    "print(f\"F1 Score Sklearn: {f1_sklearn}\")\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "print(f\"McNemar's Test Statistic: {mcnemar_stat}, p-value: {mcnemar_p_value}\")\n",
    "\n",
    "# Paired t-test on accuracies (optional, needs accuracy on same samples)\n",
    "# paired_t_stat, paired_t_p_value = stats.ttest_rel(y_pred_manual == y_true, y_pred_sklearn == y_true)\n",
    "# print(f\"Paired t-test on accuracies: t-statistic: {paired_t_stat}, p-value: {paired_t_p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwH9Q2JsOxqF",
    "outputId": "c9f88758-86e6-4e07-dc86-e931219a7cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred_sklearn,y_pred_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxtHokIYoyhR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
